{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec54737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "# Modeling\n",
    "from sklearn.metrics import f1_score, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b67dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',5000)\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4afde4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.read_csv('temp_train_data.csv')\n",
    "Y=pd.read_csv('temp_output_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81743442",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TEST=pd.read_csv('temp_test_data.csv')\n",
    "Y_TEST=pd.read_csv('temp_output_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59923b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3940, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "# Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77d77b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fti', 't3', 'tbg', 'tsh', 'tt4'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eec4fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(985, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_TEST.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "943f06b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (3940, 5)\n",
      "Model: KNeighborsClassifier()\n",
      "Best Parameters:  {'algorithm': 'brute', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Misclassified training features: 305\n",
      "f1 score: 0.9018529993640088\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      2894\n",
      "           1       0.84      0.87      0.86      1046\n",
      "\n",
      "    accuracy                           0.92      3940\n",
      "   macro avg       0.90      0.91      0.90      3940\n",
      "weighted avg       0.92      0.92      0.92      3940\n",
      "\n",
      "Roc_auc_score: 0.9064025788173857\n",
      "Misclassified test features: 170\n",
      "f1 score: 0.7805948637316562\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       718\n",
      "           1       0.68      0.67      0.68       267\n",
      "\n",
      "    accuracy                           0.83       985\n",
      "   macro avg       0.78      0.78      0.78       985\n",
      "weighted avg       0.83      0.83      0.83       985\n",
      "\n",
      "Roc_auc_score: 0.7792792087884572\n",
      "=======================================================================================\n",
      "\n",
      "Dataset shape: (3940, 5)\n",
      "Model: GaussianNB()\n",
      "Best Parameters:  {}\n",
      "Misclassified training features: 840\n",
      "f1 score: 0.6646372233226694\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87      2894\n",
      "           1       0.70      0.35      0.46      1046\n",
      "\n",
      "    accuracy                           0.79      3940\n",
      "   macro avg       0.75      0.65      0.66      3940\n",
      "weighted avg       0.77      0.79      0.76      3940\n",
      "\n",
      "Roc_auc_score: 0.6457825976074981\n",
      "Misclassified test features: 226\n",
      "f1 score: 0.6300783015607136\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86       718\n",
      "           1       0.68      0.28      0.40       267\n",
      "\n",
      "    accuracy                           0.77       985\n",
      "   macro avg       0.73      0.62      0.63       985\n",
      "weighted avg       0.76      0.77      0.73       985\n",
      "\n",
      "Roc_auc_score: 0.6179488383253523\n",
      "=======================================================================================\n",
      "\n",
      "Dataset shape: (3940, 5)\n",
      "Model: RandomForestClassifier(class_weight='balanced')\n",
      "Best Parameters:  {'criterion': 'log_loss', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_split': 15}\n",
      "Misclassified training features: 483\n",
      "f1 score: 0.8595513143401177\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91      2894\n",
      "           1       0.69      0.98      0.81      1046\n",
      "\n",
      "    accuracy                           0.88      3940\n",
      "   macro avg       0.84      0.91      0.86      3940\n",
      "weighted avg       0.91      0.88      0.88      3940\n",
      "\n",
      "Roc_auc_score: 0.9104466814045279\n",
      "Misclassified test features: 132\n",
      "f1 score: 0.8412268104686265\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.90       718\n",
      "           1       0.71      0.87      0.78       267\n",
      "\n",
      "    accuracy                           0.87       985\n",
      "   macro avg       0.83      0.87      0.84       985\n",
      "weighted avg       0.88      0.87      0.87       985\n",
      "\n",
      "Roc_auc_score: 0.8669081823208454\n",
      "=======================================================================================\n",
      "\n",
      "Dataset shape: (3940, 5)\n",
      "Model: GradientBoostingClassifier()\n",
      "Best Parameters:  {'learning_rate': 0.1, 'max_features': 'log2'}\n",
      "Misclassified training features: 512\n",
      "f1 score: 0.8463293583080629\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91      2894\n",
      "           1       0.70      0.90      0.79      1046\n",
      "\n",
      "    accuracy                           0.87      3940\n",
      "   macro avg       0.83      0.88      0.85      3940\n",
      "weighted avg       0.89      0.87      0.87      3940\n",
      "\n",
      "Roc_auc_score: 0.8791856560880889\n",
      "Misclassified test features: 132\n",
      "f1 score: 0.8380708990913439\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91       718\n",
      "           1       0.72      0.83      0.77       267\n",
      "\n",
      "    accuracy                           0.87       985\n",
      "   macro avg       0.83      0.86      0.84       985\n",
      "weighted avg       0.88      0.87      0.87       985\n",
      "\n",
      "Roc_auc_score: 0.8551453788613815\n",
      "=======================================================================================\n",
      "\n",
      "Dataset shape: (3940, 5)\n",
      "Model: MLPClassifier()\n",
      "Best Parameters:  {'activation': 'relu', 'learning_rate': 'constant', 'learning_rate_init': 0.01}\n",
      "Misclassified training features: 594\n",
      "f1 score: 0.8131266480652481\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90      2894\n",
      "           1       0.69      0.77      0.73      1046\n",
      "\n",
      "    accuracy                           0.85      3940\n",
      "   macro avg       0.80      0.82      0.81      3940\n",
      "weighted avg       0.86      0.85      0.85      3940\n",
      "\n",
      "Roc_auc_score: 0.8244214640695261\n",
      "Misclassified test features: 148\n",
      "f1 score: 0.81292412249633\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90       718\n",
      "           1       0.71      0.75      0.73       267\n",
      "\n",
      "    accuracy                           0.85       985\n",
      "   macro avg       0.81      0.82      0.81       985\n",
      "weighted avg       0.85      0.85      0.85       985\n",
      "\n",
      "Roc_auc_score: 0.8181251499692238\n",
      "=======================================================================================\n",
      "\n",
      "Dataset shape: (3940, 5)\n",
      "Model: AdaBoostClassifier()\n",
      "Best Parameters:  {'learning_rate': 0.5, 'n_estimators': 10}\n",
      "Misclassified training features: 596\n",
      "f1 score: 0.8156030373703346\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89      2894\n",
      "           1       0.68      0.80      0.74      1046\n",
      "\n",
      "    accuracy                           0.85      3940\n",
      "   macro avg       0.80      0.83      0.82      3940\n",
      "weighted avg       0.86      0.85      0.85      3940\n",
      "\n",
      "Roc_auc_score: 0.8332331282101427\n",
      "Misclassified test features: 138\n",
      "f1 score: 0.829305720198509\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90       718\n",
      "           1       0.71      0.81      0.76       267\n",
      "\n",
      "    accuracy                           0.86       985\n",
      "   macro avg       0.82      0.84      0.83       985\n",
      "weighted avg       0.87      0.86      0.86       985\n",
      "\n",
      "Roc_auc_score: 0.8427331434592553\n",
      "=======================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models={\n",
    "    'KNN classifier': KNeighborsClassifier(),\n",
    "    'naive bayes': GaussianNB(),\n",
    "    'Random Forest': RandomForestClassifier(class_weight='balanced'),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    # 'xgb': XGBClassifier(),\n",
    "    'neural_network': MLPClassifier(),\n",
    "    'adb': AdaBoostClassifier(),\n",
    "}\n",
    "\n",
    "\n",
    "params={\n",
    "    'knn classifier':{'n_neighbors':[3,4,5], 'weights':['distance'], 'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute']},\n",
    "    'naive bayes': {},\n",
    "    'random forest':{'min_samples_split':[15,20,25],'criterion':['log_loss','gini','entropy'],'max_features':['sqrt','log2'], 'max_depth':[11]},\n",
    "    'gradient boost':{'learning_rate':[0.1, 0.2,0.3], 'max_features': ['log2','sqrt']},\n",
    "    # 'xgb': {'booster': ['gbtree', 'gblinear'], 'learning_rate':[0.1,0.01,0.001],\n",
    "    #         'colsample_bylevel':[0.1], 'scale_pos_weight':[1,2],'updater':['grow_colmaker'],\n",
    "    #         'gamma':[10,20], 'max_depth':[5,7,9]},\n",
    "    'neural_network': {'activation':['relu'], 'learning_rate':['constant'], 'learning_rate_init':[0.01,0.1]},\n",
    "    'adb':{'n_estimators':[10],'learning_rate':[0.1,0.2,0.3, 0.4,0.5]},\n",
    "}\n",
    "\n",
    "train_pred_proba=[]\n",
    "test_pred_proba=[]\n",
    "\n",
    "for i in range(len(models)):\n",
    "    gd_cv= GridSearchCV(models[list(models.keys())[i]], param_grid=params[list(params.keys())[i]], scoring='accuracy', cv=3)\n",
    "    print(f\"Dataset shape: {X.shape}\")\n",
    "    \n",
    "    gd_cv.fit(X,Y)\n",
    "    \n",
    "    print(\"Model:\",models[list(models.keys())[i]])\n",
    "    print(\"Best Parameters: \",gd_cv.best_params_)\n",
    "    training_predictions=gd_cv.predict(X)\n",
    "    train_pred_proba.append(pd.Series(gd_cv.predict_proba(X)[:,1]))\n",
    "    test_predictions=gd_cv.predict(X_TEST)\n",
    "    test_pred_proba.append(pd.Series(gd_cv.predict_proba(X_TEST)[:,1]))\n",
    "    \n",
    "    \n",
    "    print(f\"Misclassified training features: {(training_predictions!=Y['disease']).sum()}\")\n",
    "    print(f\"f1 score: {f1_score(Y, training_predictions,average='macro')}\")\n",
    "    print(f\"Classification report: \\n{classification_report(Y,training_predictions)}\")\n",
    "    print(f\"Roc_auc_score: {roc_auc_score(Y,training_predictions,average='macro')}\")\n",
    "    \n",
    "    print(f\"Misclassified test features: {(test_predictions!=Y_TEST['disease']).sum()}\")\n",
    "    print(f\"f1 score: {f1_score(Y_TEST, test_predictions,average='macro')}\")\n",
    "    print(f\"Classification report: \\n{classification_report(Y_TEST,test_predictions)}\")\n",
    "    print(f\"Roc_auc_score: {roc_auc_score(Y_TEST,test_predictions,average='macro')}\")\n",
    "    \n",
    "    print(\"=======================================================================================\\n\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c46cd755",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred=pd.concat(test_pred_proba, axis=1).mean(axis=1)\n",
    "test_probabilities=pd.concat(test_pred_proba,axis=1)\n",
    "test_probabilities['mean']=final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7d730bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005448</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.013737</td>\n",
       "      <td>0.458826</td>\n",
       "      <td>0.013656</td>\n",
       "      <td>0.340404</td>\n",
       "      <td>0.118965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966375</td>\n",
       "      <td>0.876338</td>\n",
       "      <td>0.536280</td>\n",
       "      <td>0.948655</td>\n",
       "      <td>0.522086</td>\n",
       "      <td>0.835676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006907</td>\n",
       "      <td>0.005175</td>\n",
       "      <td>0.012170</td>\n",
       "      <td>0.460627</td>\n",
       "      <td>0.015293</td>\n",
       "      <td>0.340404</td>\n",
       "      <td>0.120082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042647</td>\n",
       "      <td>0.059944</td>\n",
       "      <td>0.019925</td>\n",
       "      <td>0.466670</td>\n",
       "      <td>0.086526</td>\n",
       "      <td>0.340404</td>\n",
       "      <td>0.145160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.381642</td>\n",
       "      <td>0.007877</td>\n",
       "      <td>0.880242</td>\n",
       "      <td>0.672419</td>\n",
       "      <td>0.515676</td>\n",
       "      <td>0.505547</td>\n",
       "      <td>0.522086</td>\n",
       "      <td>0.497927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000000  0.005448  0.000681  0.013737  0.458826  0.013656  0.340404   \n",
       "1  1.000000  1.000000  0.966375  0.876338  0.536280  0.948655  0.522086   \n",
       "2  0.000000  0.006907  0.005175  0.012170  0.460627  0.015293  0.340404   \n",
       "3  0.000000  0.042647  0.059944  0.019925  0.466670  0.086526  0.340404   \n",
       "4  0.381642  0.007877  0.880242  0.672419  0.515676  0.505547  0.522086   \n",
       "\n",
       "       mean  \n",
       "0  0.118965  \n",
       "1  0.835676  \n",
       "2  0.120082  \n",
       "3  0.145160  \n",
       "4  0.497927  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probabilities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1633819",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(Y_TEST, final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38aca7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresholds</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.343635</td>\n",
       "      <td>0.872081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.340590</td>\n",
       "      <td>0.871066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.347173</td>\n",
       "      <td>0.871066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.328077</td>\n",
       "      <td>0.870051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.324929</td>\n",
       "      <td>0.869036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     thresholds  accuracy\n",
       "158    0.343635  0.872081\n",
       "159    0.340590  0.871066\n",
       "157    0.347173  0.871066\n",
       "160    0.328077  0.870051\n",
       "161    0.324929  0.869036"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_ls = []\n",
    "for thres in thresholds:\n",
    "    y_pred = np.where(final_pred>thres,1,0)\n",
    "    accuracy_ls.append(accuracy_score(Y_TEST, y_pred, normalize=True))\n",
    "    \n",
    "accuracy_ls = pd.concat([pd.Series(thresholds), pd.Series(accuracy_ls)],\n",
    "                        axis=1)\n",
    "accuracy_ls.columns = ['thresholds', 'accuracy']\n",
    "accuracy_ls.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "accuracy_ls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68aa4abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresholds</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.343635</td>\n",
       "      <td>0.872081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.340590</td>\n",
       "      <td>0.871066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.347173</td>\n",
       "      <td>0.871066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.328077</td>\n",
       "      <td>0.870051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.324929</td>\n",
       "      <td>0.869036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.354341</td>\n",
       "      <td>0.868020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.354000</td>\n",
       "      <td>0.867005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.377499</td>\n",
       "      <td>0.867005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.376615</td>\n",
       "      <td>0.867005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.371765</td>\n",
       "      <td>0.867005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.369977</td>\n",
       "      <td>0.867005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.355154</td>\n",
       "      <td>0.867005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.366608</td>\n",
       "      <td>0.865990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.368432</td>\n",
       "      <td>0.865990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.374379</td>\n",
       "      <td>0.865990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.371562</td>\n",
       "      <td>0.865990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.381657</td>\n",
       "      <td>0.864975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.383051</td>\n",
       "      <td>0.864975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.388629</td>\n",
       "      <td>0.864975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.382758</td>\n",
       "      <td>0.863959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.289385</td>\n",
       "      <td>0.862944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.284414</td>\n",
       "      <td>0.861929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.288420</td>\n",
       "      <td>0.861929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.282911</td>\n",
       "      <td>0.860914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.409452</td>\n",
       "      <td>0.858883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.259151</td>\n",
       "      <td>0.858883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.252464</td>\n",
       "      <td>0.858883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.408606</td>\n",
       "      <td>0.857868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.257504</td>\n",
       "      <td>0.857868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.412196</td>\n",
       "      <td>0.857868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.246316</td>\n",
       "      <td>0.856853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.238571</td>\n",
       "      <td>0.856853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.244020</td>\n",
       "      <td>0.855838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.238506</td>\n",
       "      <td>0.855838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.445230</td>\n",
       "      <td>0.852792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.455622</td>\n",
       "      <td>0.851777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.453737</td>\n",
       "      <td>0.851777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.458875</td>\n",
       "      <td>0.850761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.447444</td>\n",
       "      <td>0.850761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.441150</td>\n",
       "      <td>0.850761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.438532</td>\n",
       "      <td>0.850761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.453534</td>\n",
       "      <td>0.850761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.439424</td>\n",
       "      <td>0.849746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.450415</td>\n",
       "      <td>0.849746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.459950</td>\n",
       "      <td>0.849746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.221728</td>\n",
       "      <td>0.848731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.460979</td>\n",
       "      <td>0.847716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.220304</td>\n",
       "      <td>0.847716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.463168</td>\n",
       "      <td>0.846701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.217536</td>\n",
       "      <td>0.845685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.478696</td>\n",
       "      <td>0.842640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.466452</td>\n",
       "      <td>0.842640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.479448</td>\n",
       "      <td>0.841624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.478313</td>\n",
       "      <td>0.841624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.470948</td>\n",
       "      <td>0.841624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.465634</td>\n",
       "      <td>0.841624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.476384</td>\n",
       "      <td>0.840609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.474156</td>\n",
       "      <td>0.840609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.469095</td>\n",
       "      <td>0.840609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.485582</td>\n",
       "      <td>0.838579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.488861</td>\n",
       "      <td>0.837563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.495863</td>\n",
       "      <td>0.837563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.483689</td>\n",
       "      <td>0.837563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.495338</td>\n",
       "      <td>0.836548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.490752</td>\n",
       "      <td>0.836548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.496456</td>\n",
       "      <td>0.836548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.497927</td>\n",
       "      <td>0.834518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.498031</td>\n",
       "      <td>0.833503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.498561</td>\n",
       "      <td>0.832487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.498484</td>\n",
       "      <td>0.831472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.500235</td>\n",
       "      <td>0.831472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.500271</td>\n",
       "      <td>0.831472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.206968</td>\n",
       "      <td>0.831472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.205864</td>\n",
       "      <td>0.830457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.203667</td>\n",
       "      <td>0.830457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.500330</td>\n",
       "      <td>0.830457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.201957</td>\n",
       "      <td>0.829442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.501480</td>\n",
       "      <td>0.829442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.501622</td>\n",
       "      <td>0.828426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.200823</td>\n",
       "      <td>0.827411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.503129</td>\n",
       "      <td>0.827411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.503339</td>\n",
       "      <td>0.826396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.507423</td>\n",
       "      <td>0.826396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.507724</td>\n",
       "      <td>0.825381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.507284</td>\n",
       "      <td>0.825381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.193312</td>\n",
       "      <td>0.823350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.192689</td>\n",
       "      <td>0.822335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.189905</td>\n",
       "      <td>0.821320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.186456</td>\n",
       "      <td>0.820305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.525525</td>\n",
       "      <td>0.817259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.512325</td>\n",
       "      <td>0.816244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.526369</td>\n",
       "      <td>0.816244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.525191</td>\n",
       "      <td>0.816244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.518750</td>\n",
       "      <td>0.815228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.517575</td>\n",
       "      <td>0.815228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.513342</td>\n",
       "      <td>0.815228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.521567</td>\n",
       "      <td>0.814213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.517657</td>\n",
       "      <td>0.814213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.519251</td>\n",
       "      <td>0.814213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.520050</td>\n",
       "      <td>0.813198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.530450</td>\n",
       "      <td>0.813198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.532280</td>\n",
       "      <td>0.813198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.535022</td>\n",
       "      <td>0.813198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.538718</td>\n",
       "      <td>0.813198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.533890</td>\n",
       "      <td>0.812183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.538737</td>\n",
       "      <td>0.812183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.542653</td>\n",
       "      <td>0.809137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.543211</td>\n",
       "      <td>0.808122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.543582</td>\n",
       "      <td>0.808122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.544771</td>\n",
       "      <td>0.807107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.547259</td>\n",
       "      <td>0.806091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.549091</td>\n",
       "      <td>0.806091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.551110</td>\n",
       "      <td>0.806091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.545549</td>\n",
       "      <td>0.806091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.545680</td>\n",
       "      <td>0.805076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.544778</td>\n",
       "      <td>0.805076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.550046</td>\n",
       "      <td>0.805076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.552980</td>\n",
       "      <td>0.805076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.559412</td>\n",
       "      <td>0.805076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.559005</td>\n",
       "      <td>0.803046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.559726</td>\n",
       "      <td>0.803046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.560159</td>\n",
       "      <td>0.802030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.561519</td>\n",
       "      <td>0.802030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.563065</td>\n",
       "      <td>0.802030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.570500</td>\n",
       "      <td>0.801015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.563210</td>\n",
       "      <td>0.801015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.569923</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.566075</td>\n",
       "      <td>0.798985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.564605</td>\n",
       "      <td>0.797970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.568229</td>\n",
       "      <td>0.797970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.568485</td>\n",
       "      <td>0.797970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.570723</td>\n",
       "      <td>0.797970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.571702</td>\n",
       "      <td>0.797970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.566029</td>\n",
       "      <td>0.796954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.571546</td>\n",
       "      <td>0.796954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.571784</td>\n",
       "      <td>0.796954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.581288</td>\n",
       "      <td>0.790863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.583177</td>\n",
       "      <td>0.789848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.587100</td>\n",
       "      <td>0.788832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.586112</td>\n",
       "      <td>0.788832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.587656</td>\n",
       "      <td>0.787817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.630439</td>\n",
       "      <td>0.785787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.590074</td>\n",
       "      <td>0.784772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.591903</td>\n",
       "      <td>0.784772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.593595</td>\n",
       "      <td>0.783756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.620774</td>\n",
       "      <td>0.783756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.602852</td>\n",
       "      <td>0.783756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.608026</td>\n",
       "      <td>0.783756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.618105</td>\n",
       "      <td>0.783756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.614070</td>\n",
       "      <td>0.782741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.609960</td>\n",
       "      <td>0.782741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.595401</td>\n",
       "      <td>0.782741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.598657</td>\n",
       "      <td>0.781726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.656848</td>\n",
       "      <td>0.775635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.655630</td>\n",
       "      <td>0.774619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.661840</td>\n",
       "      <td>0.774619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.685179</td>\n",
       "      <td>0.768528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.685717</td>\n",
       "      <td>0.767513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.709372</td>\n",
       "      <td>0.762437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.709926</td>\n",
       "      <td>0.761421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.724474</td>\n",
       "      <td>0.758376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.728559</td>\n",
       "      <td>0.757360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.151352</td>\n",
       "      <td>0.753299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.752591</td>\n",
       "      <td>0.752284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.756551</td>\n",
       "      <td>0.752284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.151205</td>\n",
       "      <td>0.752284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.739266</td>\n",
       "      <td>0.752284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.749148</td>\n",
       "      <td>0.752284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.751662</td>\n",
       "      <td>0.751269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.743958</td>\n",
       "      <td>0.751269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.760344</td>\n",
       "      <td>0.749239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.762986</td>\n",
       "      <td>0.749239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.765535</td>\n",
       "      <td>0.748223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.763445</td>\n",
       "      <td>0.748223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.761326</td>\n",
       "      <td>0.748223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.770521</td>\n",
       "      <td>0.747208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.791903</td>\n",
       "      <td>0.737056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.788633</td>\n",
       "      <td>0.736041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.792405</td>\n",
       "      <td>0.736041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.786472</td>\n",
       "      <td>0.736041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.815650</td>\n",
       "      <td>0.731980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.818501</td>\n",
       "      <td>0.731980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.828795</td>\n",
       "      <td>0.730964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.825109</td>\n",
       "      <td>0.729949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.828795</td>\n",
       "      <td>0.729949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inf</td>\n",
       "      <td>0.728934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.835676</td>\n",
       "      <td>0.728934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.135086</td>\n",
       "      <td>0.708629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.134768</td>\n",
       "      <td>0.707614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.116729</td>\n",
       "      <td>0.272081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     thresholds  accuracy\n",
       "158    0.343635  0.872081\n",
       "159    0.340590  0.871066\n",
       "157    0.347173  0.871066\n",
       "160    0.328077  0.870051\n",
       "161    0.324929  0.869036\n",
       "155    0.354341  0.868020\n",
       "156    0.354000  0.867005\n",
       "146    0.377499  0.867005\n",
       "147    0.376615  0.867005\n",
       "149    0.371765  0.867005\n",
       "151    0.369977  0.867005\n",
       "154    0.355154  0.867005\n",
       "153    0.366608  0.865990\n",
       "152    0.368432  0.865990\n",
       "148    0.374379  0.865990\n",
       "150    0.371562  0.865990\n",
       "145    0.381657  0.864975\n",
       "143    0.383051  0.864975\n",
       "142    0.388629  0.864975\n",
       "144    0.382758  0.863959\n",
       "162    0.289385  0.862944\n",
       "164    0.284414  0.861929\n",
       "163    0.288420  0.861929\n",
       "165    0.282911  0.860914\n",
       "140    0.409452  0.858883\n",
       "166    0.259151  0.858883\n",
       "168    0.252464  0.858883\n",
       "141    0.408606  0.857868\n",
       "167    0.257504  0.857868\n",
       "139    0.412196  0.857868\n",
       "169    0.246316  0.856853\n",
       "171    0.238571  0.856853\n",
       "170    0.244020  0.855838\n",
       "172    0.238506  0.855838\n",
       "135    0.445230  0.852792\n",
       "130    0.455622  0.851777\n",
       "131    0.453737  0.851777\n",
       "129    0.458875  0.850761\n",
       "134    0.447444  0.850761\n",
       "136    0.441150  0.850761\n",
       "138    0.438532  0.850761\n",
       "132    0.453534  0.850761\n",
       "137    0.439424  0.849746\n",
       "133    0.450415  0.849746\n",
       "128    0.459950  0.849746\n",
       "173    0.221728  0.848731\n",
       "127    0.460979  0.847716\n",
       "174    0.220304  0.847716\n",
       "126    0.463168  0.846701\n",
       "175    0.217536  0.845685\n",
       "118    0.478696  0.842640\n",
       "124    0.466452  0.842640\n",
       "117    0.479448  0.841624\n",
       "119    0.478313  0.841624\n",
       "122    0.470948  0.841624\n",
       "125    0.465634  0.841624\n",
       "120    0.476384  0.840609\n",
       "121    0.474156  0.840609\n",
       "123    0.469095  0.840609\n",
       "115    0.485582  0.838579\n",
       "114    0.488861  0.837563\n",
       "111    0.495863  0.837563\n",
       "116    0.483689  0.837563\n",
       "112    0.495338  0.836548\n",
       "113    0.490752  0.836548\n",
       "110    0.496456  0.836548\n",
       "109    0.497927  0.834518\n",
       "108    0.498031  0.833503\n",
       "106    0.498561  0.832487\n",
       "107    0.498484  0.831472\n",
       "105    0.500235  0.831472\n",
       "104    0.500271  0.831472\n",
       "176    0.206968  0.831472\n",
       "177    0.205864  0.830457\n",
       "178    0.203667  0.830457\n",
       "103    0.500330  0.830457\n",
       "179    0.201957  0.829442\n",
       "102    0.501480  0.829442\n",
       "101    0.501622  0.828426\n",
       "180    0.200823  0.827411\n",
       "100    0.503129  0.827411\n",
       "99     0.503339  0.826396\n",
       "97     0.507423  0.826396\n",
       "96     0.507724  0.825381\n",
       "98     0.507284  0.825381\n",
       "181    0.193312  0.823350\n",
       "182    0.192689  0.822335\n",
       "183    0.189905  0.821320\n",
       "184    0.186456  0.820305\n",
       "86     0.525525  0.817259\n",
       "95     0.512325  0.816244\n",
       "85     0.526369  0.816244\n",
       "87     0.525191  0.816244\n",
       "91     0.518750  0.815228\n",
       "93     0.517575  0.815228\n",
       "94     0.513342  0.815228\n",
       "88     0.521567  0.814213\n",
       "92     0.517657  0.814213\n",
       "90     0.519251  0.814213\n",
       "89     0.520050  0.813198\n",
       "84     0.530450  0.813198\n",
       "83     0.532280  0.813198\n",
       "81     0.535022  0.813198\n",
       "80     0.538718  0.813198\n",
       "82     0.533890  0.812183\n",
       "79     0.538737  0.812183\n",
       "78     0.542653  0.809137\n",
       "77     0.543211  0.808122\n",
       "76     0.543582  0.808122\n",
       "75     0.544771  0.807107\n",
       "71     0.547259  0.806091\n",
       "70     0.549091  0.806091\n",
       "68     0.551110  0.806091\n",
       "73     0.545549  0.806091\n",
       "72     0.545680  0.805076\n",
       "74     0.544778  0.805076\n",
       "69     0.550046  0.805076\n",
       "67     0.552980  0.805076\n",
       "65     0.559412  0.805076\n",
       "66     0.559005  0.803046\n",
       "64     0.559726  0.803046\n",
       "63     0.560159  0.802030\n",
       "62     0.561519  0.802030\n",
       "61     0.563065  0.802030\n",
       "53     0.570500  0.801015\n",
       "60     0.563210  0.801015\n",
       "54     0.569923  0.800000\n",
       "57     0.566075  0.798985\n",
       "59     0.564605  0.797970\n",
       "56     0.568229  0.797970\n",
       "55     0.568485  0.797970\n",
       "52     0.570723  0.797970\n",
       "50     0.571702  0.797970\n",
       "58     0.566029  0.796954\n",
       "51     0.571546  0.796954\n",
       "49     0.571784  0.796954\n",
       "48     0.581288  0.790863\n",
       "47     0.583177  0.789848\n",
       "45     0.587100  0.788832\n",
       "46     0.586112  0.788832\n",
       "44     0.587656  0.787817\n",
       "32     0.630439  0.785787\n",
       "43     0.590074  0.784772\n",
       "42     0.591903  0.784772\n",
       "41     0.593595  0.783756\n",
       "33     0.620774  0.783756\n",
       "38     0.602852  0.783756\n",
       "37     0.608026  0.783756\n",
       "34     0.618105  0.783756\n",
       "35     0.614070  0.782741\n",
       "36     0.609960  0.782741\n",
       "40     0.595401  0.782741\n",
       "39     0.598657  0.781726\n",
       "30     0.656848  0.775635\n",
       "31     0.655630  0.774619\n",
       "29     0.661840  0.774619\n",
       "28     0.685179  0.768528\n",
       "27     0.685717  0.767513\n",
       "26     0.709372  0.762437\n",
       "25     0.709926  0.761421\n",
       "24     0.724474  0.758376\n",
       "23     0.728559  0.757360\n",
       "185    0.151352  0.753299\n",
       "18     0.752591  0.752284\n",
       "17     0.756551  0.752284\n",
       "186    0.151205  0.752284\n",
       "22     0.739266  0.752284\n",
       "20     0.749148  0.752284\n",
       "19     0.751662  0.751269\n",
       "21     0.743958  0.751269\n",
       "16     0.760344  0.749239\n",
       "14     0.762986  0.749239\n",
       "12     0.765535  0.748223\n",
       "13     0.763445  0.748223\n",
       "15     0.761326  0.748223\n",
       "11     0.770521  0.747208\n",
       "8      0.791903  0.737056\n",
       "9      0.788633  0.736041\n",
       "7      0.792405  0.736041\n",
       "10     0.786472  0.736041\n",
       "6      0.815650  0.731980\n",
       "5      0.818501  0.731980\n",
       "3      0.828795  0.730964\n",
       "4      0.825109  0.729949\n",
       "2      0.828795  0.729949\n",
       "0           inf  0.728934\n",
       "1      0.835676  0.728934\n",
       "187    0.135086  0.708629\n",
       "188    0.134768  0.707614\n",
       "189    0.116729  0.272081"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a674702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0a58e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c1f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a659f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_class=XGBClassifier(booster='gbtree', colsample_bylevel=0.1, colsample_bynode=0.1, \n",
    "                        colsample_bytree=1, learning_rate=0.01, num_parallel_tree=1, \n",
    "                        sampling_method='uniform', scale_pos_weight=2, \n",
    "                        tree_method= 'auto', updater='grow_colmaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d58a5985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:14:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\gbm\\gbtree.cc:84: DANGER AHEAD: You have manually specified `updater` parameter. The `tree_method` parameter will be ignored. Incorrect sequence of updaters will produce undefined behavior. For common uses, we recommend using `tree_method` parameter instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=0.1, colsample_bynode=0.1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=1,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=0.1, colsample_bynode=0.1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=1,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=0.1, colsample_bynode=0.1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=1,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_class.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d4cfd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train_pred=pd.DataFrame(xgb_class.predict(X),columns=[\"Prediction\"])\n",
    "xgb_train_prob=pd.DataFrame(xgb_class.predict_proba(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f79729de",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train_pred['disease']=Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc6ac18d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blunders: 72\n"
     ]
    }
   ],
   "source": [
    "print(f\"Blunders: {xgb_train_pred[(xgb_train_pred['Prediction']!=xgb_train_pred['disease']) & (xgb_train_pred['disease']==1)].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5010e79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification: 542\n"
     ]
    }
   ],
   "source": [
    "print(f\"Misclassification: {xgb_train_pred[(xgb_train_pred['Prediction']!=xgb_train_pred['disease'])].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "739da14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train_pred2=xgb_train_pred.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c435ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7818892"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xgb_train_prob[0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11e2ceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train_pred2['Prediction']=np.where(xgb_train_prob[0]>0.58,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f49e308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification: 543\n"
     ]
    }
   ],
   "source": [
    "print(f\"Misclassification: {xgb_train_pred2[(xgb_train_pred2['Prediction']!=xgb_train_pred2['disease'])].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08d5efed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blunders: 24\n"
     ]
    }
   ],
   "source": [
    "print(f\"Blunders: {xgb_train_pred2[(xgb_train_pred2['Prediction']!=xgb_train_pred2['disease']) & (xgb_train_pred2['disease']==1)].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8604adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3940, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_train_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4866086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90      2894\n",
      "           1       0.66      0.98      0.79      1046\n",
      "\n",
      "    accuracy                           0.86      3940\n",
      "   macro avg       0.83      0.90      0.84      3940\n",
      "weighted avg       0.90      0.86      0.87      3940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y,xgb_train_pred2['Prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376eff02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68972659",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test_pred=pd.DataFrame(xgb_class.predict(X_TEST),columns=['Prediction'])\n",
    "xgb_test_prob=pd.DataFrame(xgb_class.predict_proba(X_TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc819cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test_pred['disease']=Y_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6cd328b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blunders: 31\n"
     ]
    }
   ],
   "source": [
    "print(f\"Blunders: {xgb_test_pred[(xgb_test_pred['Prediction']!=xgb_test_pred['disease']) & (xgb_test_pred['disease']==1)].shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "877fe293",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blunders: 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.553530</td>\n",
       "      <td>0.446470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.516784</td>\n",
       "      <td>0.483216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.548764</td>\n",
       "      <td>0.451236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.555834</td>\n",
       "      <td>0.444166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.512452</td>\n",
       "      <td>0.487548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1\n",
       "6    0.553530  0.446470\n",
       "44   0.516784  0.483216\n",
       "130  0.548764  0.451236\n",
       "218  0.555834  0.444166\n",
       "278  0.512452  0.487548"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Blunders: {xgb_test_prob[(xgb_test_pred['Prediction']!=xgb_test_pred['disease']) & (xgb_test_pred['disease']==1)].shape[0]}\")\n",
    "xgb_test_prob[(xgb_test_pred['Prediction']!=xgb_test_pred['disease']) & (xgb_test_pred['disease']==1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ea9adc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassifications: 129\n"
     ]
    }
   ],
   "source": [
    "print(f\"Misclassifications: {xgb_test_pred[(xgb_test_pred['Prediction']!=xgb_test_pred['disease'])].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "947bf0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassifications: 129\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.390049</td>\n",
       "      <td>0.609951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.553530</td>\n",
       "      <td>0.446470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.406054</td>\n",
       "      <td>0.593946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.325631</td>\n",
       "      <td>0.674369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.261276</td>\n",
       "      <td>0.738724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1\n",
       "4   0.390049  0.609951\n",
       "6   0.553530  0.446470\n",
       "19  0.406054  0.593946\n",
       "22  0.325631  0.674369\n",
       "27  0.261276  0.738724"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Misclassifications: {xgb_test_prob[(xgb_test_pred['Prediction']!=xgb_test_pred['disease'])].shape[0]}\")\n",
    "xgb_test_prob[(xgb_test_pred['Prediction']!=xgb_test_pred['disease'])].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e461bfe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7818892"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_test_prob[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbc633da",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test_pred2=xgb_test_pred.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29340ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test_pred2['Prediction']=np.where(xgb_test_prob[0]>0.58,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a336a037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassifications: 133\n"
     ]
    }
   ],
   "source": [
    "print(f\"Misclassifications: {xgb_test_pred2[(xgb_test_pred2['Prediction']!=xgb_test_pred2['disease'])].shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e1577c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blunders: 22\n"
     ]
    }
   ],
   "source": [
    "print(f\"Blunders: {xgb_test_pred[(xgb_test_pred2['Prediction']!=xgb_test_pred2['disease']) & (xgb_test_pred2['disease']==1)].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0db0c65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       718\n",
      "           1       0.69      0.92      0.79       267\n",
      "\n",
      "    accuracy                           0.86       985\n",
      "   macro avg       0.83      0.88      0.84       985\n",
      "weighted avg       0.89      0.86      0.87       985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(xgb_test_pred2['disease'],xgb_test_pred2['Prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1385855e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7244802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
